{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "sixth-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/psolikov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import textdistance\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "faced-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spylls.hunspell import Dictionary\n",
    "\n",
    "dictionary = Dictionary.from_files('en_US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "insured-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return word_tokenize(s)\n",
    "\n",
    "def get_variants(token):\n",
    "    if dictionary.lookup(token):\n",
    "        return None\n",
    "    return list(dictionary.suggest(token))\n",
    "\n",
    "def get_distance(token, variant):\n",
    "    d = []\n",
    "    max_len = max(len(token), len(variant))\n",
    "    d.append(textdistance.hamming(token, variant) / max_len)\n",
    "    d.append(textdistance.mlipns(token, variant) / max_len)\n",
    "    d.append(textdistance.levenshtein(token, variant) / max_len)\n",
    "    d.append(textdistance.damerau_levenshtein(token, variant) / max_len)\n",
    "    d.append(1 - textdistance.jaro_winkler(token, variant))\n",
    "    d.append(1 - textdistance.strcmp95(token, variant))\n",
    "    d.append(textdistance.mra(token, variant) / max_len)\n",
    "    return np.mean(d)\n",
    "\n",
    "def get_indexes(distances):\n",
    "    sorted(zip(variants))\n",
    "\n",
    "def get_best_variant(token, variants):\n",
    "    distances = []\n",
    "    for variant in variants:\n",
    "        distances.append(get_distance(token, variant))\n",
    "    tuples = sorted(zip(distances, variants))\n",
    "    return tuples[0][1]\n",
    "    \n",
    "\n",
    "def correct_text(s):\n",
    "    tokens = tokenize(s)\n",
    "    for token in tokens:\n",
    "        variants = get_variants(token)\n",
    "        if not variants:\n",
    "            continue\n",
    "        variant = get_best_variant(token, variants)\n",
    "        print(f\"\\\"{token}\\\" -> \\\"{variant}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "appointed-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_text(\"The score is normalized such that 0 means an exact match and 1 means there is no similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "wrong-cologne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"scsore\" -> \"score\"\n"
     ]
    }
   ],
   "source": [
    "correct_text(\"The scsore is normalized such that 0 means an exact match and 1 means there is no similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "romance-chinese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"normalised\" -> \"normalized\"\n",
      "\"mdans\" -> \"means\"\n"
     ]
    }
   ],
   "source": [
    "correct_text(\"The score is normalised such that 0 mdans an exact match and 1 means there is no similarity\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
